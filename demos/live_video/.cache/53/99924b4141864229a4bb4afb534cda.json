{"id":"node_modules/@tensorflow-models/pose-detection/shared/calculators/image_utils.ts","dependencies":[{"name":"C:\\xampp\\htdocs\\pose-detection\\demos\\live_video\\package.json","includedInParent":true,"mtime":1634830278911},{"name":"C:\\xampp\\htdocs\\pose-detection\\demos\\live_video\\.babelrc","includedInParent":true,"mtime":1634828519177},{"name":"@tensorflow/tfjs-core","loc":{"line":26,"column":30},"parent":"C:\\xampp\\htdocs\\pose-detection\\demos\\live_video\\node_modules\\@tensorflow-models\\pose-detection\\shared\\calculators\\image_utils.ts","resolved":"C:\\xampp\\htdocs\\pose-detection\\demos\\live_video\\node_modules\\@tensorflow\\tfjs-core\\dist\\index.js"}],"generated":{"js":"\"use strict\";\r\nvar __importStar = (this && this.__importStar) || function (mod) {\r\n    if (mod && mod.__esModule) return mod;\r\n    var result = {};\r\n    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];\r\n    result[\"default\"] = mod;\r\n    return result;\r\n};\r\nexports.__esModule = true;\r\n/**\r\n * @license\r\n * Copyright 2021 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * https://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\nvar tf = __importStar(require(\"@tensorflow/tfjs-core\"));\r\nfunction getImageSize(input) {\r\n    if (input instanceof tf.Tensor) {\r\n        return { height: input.shape[0], width: input.shape[1] };\r\n    }\r\n    else {\r\n        return { height: input.height, width: input.width };\r\n    }\r\n}\r\nexports.getImageSize = getImageSize;\r\n/**\r\n * Normalizes the provided angle to the range -pi to pi.\r\n * @param angle The angle in radians to be normalized.\r\n */\r\nfunction normalizeRadians(angle) {\r\n    return angle - 2 * Math.PI * Math.floor((angle + Math.PI) / (2 * Math.PI));\r\n}\r\nexports.normalizeRadians = normalizeRadians;\r\n/**\r\n * Transform value ranges.\r\n * @param fromMin Min of original value range.\r\n * @param fromMax Max of original value range.\r\n * @param toMin New min of transformed value range.\r\n * @param toMax New max of transformed value range.\r\n */\r\nfunction transformValueRange(fromMin, fromMax, toMin, toMax) {\r\n    var fromRange = fromMax - fromMin;\r\n    var toRange = toMax - toMin;\r\n    if (fromRange === 0) {\r\n        throw new Error(\"Original min and max are both \" + fromMin + \", range cannot be 0.\");\r\n    }\r\n    var scale = toRange / fromRange;\r\n    var offset = toMin - fromMin * scale;\r\n    return { scale: scale, offset: offset };\r\n}\r\nexports.transformValueRange = transformValueRange;\r\n/**\r\n * Convert an image to an image tensor representation.\r\n *\r\n * The image tensor has a shape [1, height, width, colorChannel].\r\n *\r\n * @param input An image, video frame, or image tensor.\r\n */\r\nfunction toImageTensor(input) {\r\n    return input instanceof tf.Tensor ? input : tf.browser.fromPixels(input);\r\n}\r\nexports.toImageTensor = toImageTensor;\r\n/**\r\n * Padding ratio of left, top, right, bottom, based on the output dimensions.\r\n *\r\n * The padding values are non-zero only when the \"keep_aspect_ratio\" is true.\r\n *\r\n * For instance, when the input image is 10x10 (width x height) and the\r\n * output dimensions is 20x40 and \"keep_aspect_ratio\" is true, we should scale\r\n * the input image to 20x20 and places it in the middle of the output image with\r\n * an equal padding of 10 pixels at the top and the bottom. The result is\r\n * therefore {left: 0, top: 0.25, right: 0, bottom: 0.25} (10/40 = 0.25f).\r\n * @param roi The original rectangle to pad.\r\n * @param targetSize The target width and height of the result rectangle.\r\n * @param keepAspectRatio Whether keep aspect ratio. Default to false.\r\n */\r\nfunction padRoi(roi, targetSize, keepAspectRatio) {\r\n    if (keepAspectRatio === void 0) { keepAspectRatio = false; }\r\n    if (!keepAspectRatio) {\r\n        return { top: 0, left: 0, right: 0, bottom: 0 };\r\n    }\r\n    var targetH = targetSize.height;\r\n    var targetW = targetSize.width;\r\n    validateSize(targetSize, 'targetSize');\r\n    validateSize(roi, 'roi');\r\n    var tensorAspectRatio = targetH / targetW;\r\n    var roiAspectRatio = roi.height / roi.width;\r\n    var newWidth;\r\n    var newHeight;\r\n    var horizontalPadding = 0;\r\n    var verticalPadding = 0;\r\n    if (tensorAspectRatio > roiAspectRatio) {\r\n        // pad height;\r\n        newWidth = roi.width;\r\n        newHeight = roi.width * tensorAspectRatio;\r\n        verticalPadding = (1 - roiAspectRatio / tensorAspectRatio) / 2;\r\n    }\r\n    else {\r\n        // pad width.\r\n        newWidth = roi.height / tensorAspectRatio;\r\n        newHeight = roi.height;\r\n        horizontalPadding = (1 - tensorAspectRatio / roiAspectRatio) / 2;\r\n    }\r\n    roi.width = newWidth;\r\n    roi.height = newHeight;\r\n    return {\r\n        top: verticalPadding,\r\n        left: horizontalPadding,\r\n        right: horizontalPadding,\r\n        bottom: verticalPadding\r\n    };\r\n}\r\nexports.padRoi = padRoi;\r\n/**\r\n * Get the rectangle information of an image, including xCenter, yCenter, width,\r\n * height and rotation.\r\n *\r\n * @param imageSize imageSize is used to calculate the rectangle.\r\n * @param normRect Optional. If normRect is not null, it will be used to get\r\n *     a subarea rectangle information in the image. `imageSize` is used to\r\n *     calculate the actual non-normalized coordinates.\r\n */\r\nfunction getRoi(imageSize, normRect) {\r\n    if (normRect) {\r\n        return {\r\n            xCenter: normRect.xCenter * imageSize.width,\r\n            yCenter: normRect.yCenter * imageSize.height,\r\n            width: normRect.width * imageSize.width,\r\n            height: normRect.height * imageSize.height,\r\n            rotation: normRect.rotation\r\n        };\r\n    }\r\n    else {\r\n        return {\r\n            xCenter: 0.5 * imageSize.width,\r\n            yCenter: 0.5 * imageSize.height,\r\n            width: imageSize.width,\r\n            height: imageSize.height,\r\n            rotation: 0\r\n        };\r\n    }\r\n}\r\nexports.getRoi = getRoi;\r\n/**\r\n * Generate the projective transformation matrix to be used for `tf.transform`.\r\n *\r\n * See more documentation in `tf.transform`.\r\n *\r\n * @param subRect The rectangle to generate the projective transformation matrix\r\n *     for.\r\n * @param imageSize The original image height and width.\r\n * @param flipHorizontally Whether flip the image horizontally.\r\n * @param inputResolution The target height and width.\r\n */\r\nfunction getProjectiveTransformMatrix(subRect, imageSize, flipHorizontally, inputResolution) {\r\n    validateSize(inputResolution, 'inputResolution');\r\n    // Ref:\r\n    // https://github.com/google/mediapipe/blob/master/mediapipe/calculators/tensor/image_to_tensor_utils.cc\r\n    // The resulting matrix is multiplication of below matrices:\r\n    // M = postScaleMatrix * translateMatrix * rotateMatrix * flipMatrix *\r\n    //     scaleMatrix * initialTranslateMatrix\r\n    //\r\n    // For any point in the transformed image p, we can use the above matrix to\r\n    // calculate the projected point in the original image p'. So that:\r\n    // p' = p * M;\r\n    // Note: The transform matrix below assumes image coordinates is normalized\r\n    // to [0, 1] range.\r\n    // postScaleMatrix: Matrix to scale x, y to [0, 1] range\r\n    //   | g  0  0 |\r\n    //   | 0  h  0 |\r\n    //   | 0  0  1 |\r\n    var g = 1 / imageSize.width;\r\n    var h = 1 / imageSize.height;\r\n    // translateMatrix: Matrix to move the center to the subRect center.\r\n    //   | 1  0  e |\r\n    //   | 0  1  f |\r\n    //   | 0  0  1 |\r\n    var e = subRect.xCenter;\r\n    var f = subRect.yCenter;\r\n    // rotateMatrix: Matrix to do rotate the image around the subRect center.\r\n    //   | c -d  0 |\r\n    //   | d  c  0 |\r\n    //   | 0  0  1 |\r\n    var c = Math.cos(subRect.rotation);\r\n    var d = Math.sin(subRect.rotation);\r\n    // flipMatrix: Matrix for optional horizontal flip around the subRect center.\r\n    //   | fl 0  0 |\r\n    //   | 0  1  0 |\r\n    //   | 0  0  1 |\r\n    var flip = flipHorizontally ? -1 : 1;\r\n    // scaleMatrix: Matrix to scale x, y to subRect size.\r\n    //   | a  0  0 |\r\n    //   | 0  b  0 |\r\n    //   | 0  0  1 |\r\n    var a = subRect.width;\r\n    var b = subRect.height;\r\n    // initialTranslateMatrix: Matrix convert x, y to [-0.5, 0.5] range.\r\n    //   | 1  0 -0.5 |\r\n    //   | 0  1 -0.5 |\r\n    //   | 0  0  1   |\r\n    // M is a 3 by 3 matrix denoted by:\r\n    // | a0  a1  a2 |\r\n    // | b0  b1  b2 |\r\n    // | 0   0   1  |\r\n    // To use M with regular x, y coordinates, we need to normalize them first.\r\n    // Because x' = a0 * x + a1 * y + a2, y' = b0 * x + b1 * y + b2,\r\n    // we need to use factor (1/inputResolution.width) to normalize x for a0 and\r\n    // b0, similarly we need to use factor (1/inputResolution.height) to normalize\r\n    // y for a1 and b1.\r\n    // Also at the end, we need to de-normalize x' and y' to regular coordinates.\r\n    // So we need to use factor imageSize.width for a0, a1 and a2, similarly\r\n    // we need to use factor imageSize.height for b0, b1 and b2.\r\n    var a0 = (1 / inputResolution.width) * a * c * flip * g * imageSize.width;\r\n    var a1 = (1 / inputResolution.height) * -b * d * g * imageSize.width;\r\n    var a2 = (-0.5 * a * c * flip + 0.5 * b * d + e) * g * imageSize.width;\r\n    var b0 = (1 / inputResolution.width) * a * d * flip * h * imageSize.height;\r\n    var b1 = (1 / inputResolution.height) * b * c * h * imageSize.height;\r\n    var b2 = (-0.5 * b * c - 0.5 * a * d * flip + f) * h * imageSize.height;\r\n    return [a0, a1, a2, b0, b1, b2, 0, 0];\r\n}\r\nexports.getProjectiveTransformMatrix = getProjectiveTransformMatrix;\r\nfunction validateSize(size, name) {\r\n    tf.util.assert(size.width !== 0, function () { return name + \" width cannot be 0.\"; });\r\n    tf.util.assert(size.height !== 0, function () { return name + \" height cannot be 0.\"; });\r\n}\r\n"},"sourceMaps":{"js":{"version":3,"file":"image_utils.js","sourceRoot":"","sources":["node_modules/@tensorflow-models/pose-detection/shared/calculators/image_utils.ts"],"names":[],"mappings":";;;;;;;;;AAAA;;;;;;;;;;;;;;;GAeG;AACH,wDAA4C;AAK5C,SAAgB,YAAY,CAAC,KAAoB;IAC/C,IAAI,KAAK,YAAY,EAAE,CAAC,MAAM,EAAE;QAC9B,OAAO,EAAC,MAAM,EAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,KAAK,EAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,EAAC,CAAC;KACxD;SAAM;QACL,OAAO,EAAC,MAAM,EAAE,KAAK,CAAC,MAAM,EAAE,KAAK,EAAE,KAAK,CAAC,KAAK,EAAC,CAAC;KACnD;AACH,CAAC;AAND,oCAMC;AAED;;;GAGG;AACH,SAAgB,gBAAgB,CAAC,KAAa;IAC5C,OAAO,KAAK,GAAG,CAAC,GAAG,IAAI,CAAC,EAAE,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,KAAK,GAAG,IAAI,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC,EAAE,CAAC,CAAC,CAAC;AAC7E,CAAC;AAFD,4CAEC;AAED;;;;;;GAMG;AACH,SAAgB,mBAAmB,CAC/B,OAAe,EAAE,OAAe,EAAE,KAAa,EAC/C,KAAa;IACf,IAAM,SAAS,GAAG,OAAO,GAAG,OAAO,CAAC;IACpC,IAAM,OAAO,GAAG,KAAK,GAAG,KAAK,CAAC;IAE9B,IAAI,SAAS,KAAK,CAAC,EAAE;QACnB,MAAM,IAAI,KAAK,CACX,mCAAiC,OAAO,yBAAsB,CAAC,CAAC;KACrE;IAED,IAAM,KAAK,GAAG,OAAO,GAAG,SAAS,CAAC;IAClC,IAAM,MAAM,GAAG,KAAK,GAAG,OAAO,GAAG,KAAK,CAAC;IACvC,OAAO,EAAC,KAAK,OAAA,EAAE,MAAM,QAAA,EAAC,CAAC;AACzB,CAAC;AAdD,kDAcC;AAED;;;;;;GAMG;AACH,SAAgB,aAAa,CAAC,KACkC;IAC9D,OAAO,KAAK,YAAY,EAAE,CAAC,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,OAAO,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC;AAC3E,CAAC;AAHD,sCAGC;AAED;;;;;;;;;;;;;GAaG;AACH,SAAgB,MAAM,CAClB,GAAS,EAAE,UAA2B,EAAE,eAAuB;IAAvB,gCAAA,EAAA,uBAAuB;IACjE,IAAI,CAAC,eAAe,EAAE;QACpB,OAAO,EAAC,GAAG,EAAE,CAAC,EAAE,IAAI,EAAE,CAAC,EAAE,KAAK,EAAE,CAAC,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC;KAC/C;IAED,IAAM,OAAO,GAAG,UAAU,CAAC,MAAM,CAAC;IAClC,IAAM,OAAO,GAAG,UAAU,CAAC,KAAK,CAAC;IAEjC,YAAY,CAAC,UAAU,EAAE,YAAY,CAAC,CAAC;IACvC,YAAY,CAAC,GAAG,EAAE,KAAK,CAAC,CAAC;IAEzB,IAAM,iBAAiB,GAAG,OAAO,GAAG,OAAO,CAAC;IAC5C,IAAM,cAAc,GAAG,GAAG,CAAC,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC;IAC9C,IAAI,QAAQ,CAAC;IACb,IAAI,SAAS,CAAC;IACd,IAAI,iBAAiB,GAAG,CAAC,CAAC;IAC1B,IAAI,eAAe,GAAG,CAAC,CAAC;IACxB,IAAI,iBAAiB,GAAG,cAAc,EAAE;QACtC,cAAc;QACd,QAAQ,GAAG,GAAG,CAAC,KAAK,CAAC;QACrB,SAAS,GAAG,GAAG,CAAC,KAAK,GAAG,iBAAiB,CAAC;QAC1C,eAAe,GAAG,CAAC,CAAC,GAAG,cAAc,GAAG,iBAAiB,CAAC,GAAG,CAAC,CAAC;KAChE;SAAM;QACL,aAAa;QACb,QAAQ,GAAG,GAAG,CAAC,MAAM,GAAG,iBAAiB,CAAC;QAC1C,SAAS,GAAG,GAAG,CAAC,MAAM,CAAC;QACvB,iBAAiB,GAAG,CAAC,CAAC,GAAG,iBAAiB,GAAG,cAAc,CAAC,GAAG,CAAC,CAAC;KAClE;IAED,GAAG,CAAC,KAAK,GAAG,QAAQ,CAAC;IACrB,GAAG,CAAC,MAAM,GAAG,SAAS,CAAC;IAEvB,OAAO;QACL,GAAG,EAAE,eAAe;QACpB,IAAI,EAAE,iBAAiB;QACvB,KAAK,EAAE,iBAAiB;QACxB,MAAM,EAAE,eAAe;KACxB,CAAC;AACJ,CAAC;AAvCD,wBAuCC;AAED;;;;;;;;GAQG;AACH,SAAgB,MAAM,CAAC,SAAoB,EAAE,QAAe;IAC1D,IAAI,QAAQ,EAAE;QACZ,OAAO;YACL,OAAO,EAAE,QAAQ,CAAC,OAAO,GAAG,SAAS,CAAC,KAAK;YAC3C,OAAO,EAAE,QAAQ,CAAC,OAAO,GAAG,SAAS,CAAC,MAAM;YAC5C,KAAK,EAAE,QAAQ,CAAC,KAAK,GAAG,SAAS,CAAC,KAAK;YACvC,MAAM,EAAE,QAAQ,CAAC,MAAM,GAAG,SAAS,CAAC,MAAM;YAC1C,QAAQ,EAAE,QAAQ,CAAC,QAAQ;SAC5B,CAAC;KACH;SAAM;QACL,OAAO;YACL,OAAO,EAAE,GAAG,GAAG,SAAS,CAAC,KAAK;YAC9B,OAAO,EAAE,GAAG,GAAG,SAAS,CAAC,MAAM;YAC/B,KAAK,EAAE,SAAS,CAAC,KAAK;YACtB,MAAM,EAAE,SAAS,CAAC,MAAM;YACxB,QAAQ,EAAE,CAAC;SACZ,CAAC;KACH;AACH,CAAC;AAlBD,wBAkBC;AAED;;;;;;;;;;GAUG;AACH,SAAgB,4BAA4B,CACxC,OAAa,EAAE,SAAoB,EAAE,gBAAyB,EAC9D,eAAgC;IAElC,YAAY,CAAC,eAAe,EAAE,iBAAiB,CAAC,CAAC;IAEjD,OAAO;IACP,wGAAwG;IACxG,4DAA4D;IAC5D,sEAAsE;IACtE,2CAA2C;IAC3C,EAAE;IACF,2EAA2E;IAC3E,mEAAmE;IACnE,cAAc;IACd,2EAA2E;IAC3E,mBAAmB;IAEnB,wDAAwD;IACxD,gBAAgB;IAChB,gBAAgB;IAChB,gBAAgB;IAChB,IAAM,CAAC,GAAG,CAAC,GAAG,SAAS,CAAC,KAAK,CAAC;IAC9B,IAAM,CAAC,GAAG,CAAC,GAAG,SAAS,CAAC,MAAM,CAAC;IAE/B,oEAAoE;IACpE,gBAAgB;IAChB,gBAAgB;IAChB,gBAAgB;IAChB,IAAM,CAAC,GAAG,OAAO,CAAC,OAAO,CAAC;IAC1B,IAAM,CAAC,GAAG,OAAO,CAAC,OAAO,CAAC;IAE1B,yEAAyE;IACzE,gBAAgB;IAChB,gBAAgB;IAChB,gBAAgB;IAChB,IAAM,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC;IACrC,IAAM,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC;IAErC,6EAA6E;IAC7E,gBAAgB;IAChB,gBAAgB;IAChB,gBAAgB;IAChB,IAAM,IAAI,GAAG,gBAAgB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IAEvC,qDAAqD;IACrD,gBAAgB;IAChB,gBAAgB;IAChB,gBAAgB;IAChB,IAAM,CAAC,GAAG,OAAO,CAAC,KAAK,CAAC;IACxB,IAAM,CAAC,GAAG,OAAO,CAAC,MAAM,CAAC;IAEzB,oEAAoE;IACpE,kBAAkB;IAClB,kBAAkB;IAClB,kBAAkB;IAElB,mCAAmC;IACnC,iBAAiB;IACjB,iBAAiB;IACjB,iBAAiB;IACjB,2EAA2E;IAC3E,gEAAgE;IAChE,4EAA4E;IAC5E,8EAA8E;IAC9E,mBAAmB;IACnB,6EAA6E;IAC7E,wEAAwE;IACxE,4DAA4D;IAC5D,IAAM,EAAE,GAAG,CAAC,CAAC,GAAG,eAAe,CAAC,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,IAAI,GAAG,CAAC,GAAG,SAAS,CAAC,KAAK,CAAC;IAC5E,IAAM,EAAE,GAAG,CAAC,CAAC,GAAG,eAAe,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,SAAS,CAAC,KAAK,CAAC;IACvE,IAAM,EAAE,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,GAAG,IAAI,GAAG,GAAG,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,SAAS,CAAC,KAAK,CAAC;IACzE,IAAM,EAAE,GAAG,CAAC,CAAC,GAAG,eAAe,CAAC,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,IAAI,GAAG,CAAC,GAAG,SAAS,CAAC,MAAM,CAAC;IAC7E,IAAM,EAAE,GAAG,CAAC,CAAC,GAAG,eAAe,CAAC,MAAM,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,SAAS,CAAC,MAAM,CAAC;IACvE,IAAM,EAAE,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,GAAG,GAAG,GAAG,CAAC,GAAG,CAAC,GAAG,IAAI,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,SAAS,CAAC,MAAM,CAAC;IAE1E,OAAO,CAAC,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;AACxC,CAAC;AA7ED,oEA6EC;AAED,SAAS,YAAY,CAAC,IAAqC,EAAE,IAAY;IACvE,EAAE,CAAC,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,KAAK,KAAK,CAAC,EAAE,cAAM,OAAG,IAAI,wBAAqB,EAA5B,CAA4B,CAAC,CAAC;IACrE,EAAE,CAAC,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,MAAM,KAAK,CAAC,EAAE,cAAM,OAAG,IAAI,yBAAsB,EAA7B,CAA6B,CAAC,CAAC;AACzE,CAAC","sourcesContent":["/**\r\n * @license\r\n * Copyright 2021 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * https://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\nimport * as tf from '@tensorflow/tfjs-core';\r\n\r\nimport {DetectorInput, ImageSize, InputResolution, Padding, ValueTransform} from './interfaces/common_interfaces';\r\nimport {Rect} from './interfaces/shape_interfaces';\r\n\r\nexport function getImageSize(input: DetectorInput): ImageSize {\r\n  if (input instanceof tf.Tensor) {\r\n    return {height: input.shape[0], width: input.shape[1]};\r\n  } else {\r\n    return {height: input.height, width: input.width};\r\n  }\r\n}\r\n\r\n/**\r\n * Normalizes the provided angle to the range -pi to pi.\r\n * @param angle The angle in radians to be normalized.\r\n */\r\nexport function normalizeRadians(angle: number): number {\r\n  return angle - 2 * Math.PI * Math.floor((angle + Math.PI) / (2 * Math.PI));\r\n}\r\n\r\n/**\r\n * Transform value ranges.\r\n * @param fromMin Min of original value range.\r\n * @param fromMax Max of original value range.\r\n * @param toMin New min of transformed value range.\r\n * @param toMax New max of transformed value range.\r\n */\r\nexport function transformValueRange(\r\n    fromMin: number, fromMax: number, toMin: number,\r\n    toMax: number): ValueTransform {\r\n  const fromRange = fromMax - fromMin;\r\n  const toRange = toMax - toMin;\r\n\r\n  if (fromRange === 0) {\r\n    throw new Error(\r\n        `Original min and max are both ${fromMin}, range cannot be 0.`);\r\n  }\r\n\r\n  const scale = toRange / fromRange;\r\n  const offset = toMin - fromMin * scale;\r\n  return {scale, offset};\r\n}\r\n\r\n/**\r\n * Convert an image to an image tensor representation.\r\n *\r\n * The image tensor has a shape [1, height, width, colorChannel].\r\n *\r\n * @param input An image, video frame, or image tensor.\r\n */\r\nexport function toImageTensor(input: tf.Tensor3D|ImageData|HTMLVideoElement|\r\n                              HTMLImageElement|HTMLCanvasElement) {\r\n  return input instanceof tf.Tensor ? input : tf.browser.fromPixels(input);\r\n}\r\n\r\n/**\r\n * Padding ratio of left, top, right, bottom, based on the output dimensions.\r\n *\r\n * The padding values are non-zero only when the \"keep_aspect_ratio\" is true.\r\n *\r\n * For instance, when the input image is 10x10 (width x height) and the\r\n * output dimensions is 20x40 and \"keep_aspect_ratio\" is true, we should scale\r\n * the input image to 20x20 and places it in the middle of the output image with\r\n * an equal padding of 10 pixels at the top and the bottom. The result is\r\n * therefore {left: 0, top: 0.25, right: 0, bottom: 0.25} (10/40 = 0.25f).\r\n * @param roi The original rectangle to pad.\r\n * @param targetSize The target width and height of the result rectangle.\r\n * @param keepAspectRatio Whether keep aspect ratio. Default to false.\r\n */\r\nexport function padRoi(\r\n    roi: Rect, targetSize: InputResolution, keepAspectRatio = false): Padding {\r\n  if (!keepAspectRatio) {\r\n    return {top: 0, left: 0, right: 0, bottom: 0};\r\n  }\r\n\r\n  const targetH = targetSize.height;\r\n  const targetW = targetSize.width;\r\n\r\n  validateSize(targetSize, 'targetSize');\r\n  validateSize(roi, 'roi');\r\n\r\n  const tensorAspectRatio = targetH / targetW;\r\n  const roiAspectRatio = roi.height / roi.width;\r\n  let newWidth;\r\n  let newHeight;\r\n  let horizontalPadding = 0;\r\n  let verticalPadding = 0;\r\n  if (tensorAspectRatio > roiAspectRatio) {\r\n    // pad height;\r\n    newWidth = roi.width;\r\n    newHeight = roi.width * tensorAspectRatio;\r\n    verticalPadding = (1 - roiAspectRatio / tensorAspectRatio) / 2;\r\n  } else {\r\n    // pad width.\r\n    newWidth = roi.height / tensorAspectRatio;\r\n    newHeight = roi.height;\r\n    horizontalPadding = (1 - tensorAspectRatio / roiAspectRatio) / 2;\r\n  }\r\n\r\n  roi.width = newWidth;\r\n  roi.height = newHeight;\r\n\r\n  return {\r\n    top: verticalPadding,\r\n    left: horizontalPadding,\r\n    right: horizontalPadding,\r\n    bottom: verticalPadding\r\n  };\r\n}\r\n\r\n/**\r\n * Get the rectangle information of an image, including xCenter, yCenter, width,\r\n * height and rotation.\r\n *\r\n * @param imageSize imageSize is used to calculate the rectangle.\r\n * @param normRect Optional. If normRect is not null, it will be used to get\r\n *     a subarea rectangle information in the image. `imageSize` is used to\r\n *     calculate the actual non-normalized coordinates.\r\n */\r\nexport function getRoi(imageSize: ImageSize, normRect?: Rect): Rect {\r\n  if (normRect) {\r\n    return {\r\n      xCenter: normRect.xCenter * imageSize.width,\r\n      yCenter: normRect.yCenter * imageSize.height,\r\n      width: normRect.width * imageSize.width,\r\n      height: normRect.height * imageSize.height,\r\n      rotation: normRect.rotation\r\n    };\r\n  } else {\r\n    return {\r\n      xCenter: 0.5 * imageSize.width,\r\n      yCenter: 0.5 * imageSize.height,\r\n      width: imageSize.width,\r\n      height: imageSize.height,\r\n      rotation: 0\r\n    };\r\n  }\r\n}\r\n\r\n/**\r\n * Generate the projective transformation matrix to be used for `tf.transform`.\r\n *\r\n * See more documentation in `tf.transform`.\r\n *\r\n * @param subRect The rectangle to generate the projective transformation matrix\r\n *     for.\r\n * @param imageSize The original image height and width.\r\n * @param flipHorizontally Whether flip the image horizontally.\r\n * @param inputResolution The target height and width.\r\n */\r\nexport function getProjectiveTransformMatrix(\r\n    subRect: Rect, imageSize: ImageSize, flipHorizontally: boolean,\r\n    inputResolution: InputResolution):\r\n    [number, number, number, number, number, number, number, number] {\r\n  validateSize(inputResolution, 'inputResolution');\r\n\r\n  // Ref:\r\n  // https://github.com/google/mediapipe/blob/master/mediapipe/calculators/tensor/image_to_tensor_utils.cc\r\n  // The resulting matrix is multiplication of below matrices:\r\n  // M = postScaleMatrix * translateMatrix * rotateMatrix * flipMatrix *\r\n  //     scaleMatrix * initialTranslateMatrix\r\n  //\r\n  // For any point in the transformed image p, we can use the above matrix to\r\n  // calculate the projected point in the original image p'. So that:\r\n  // p' = p * M;\r\n  // Note: The transform matrix below assumes image coordinates is normalized\r\n  // to [0, 1] range.\r\n\r\n  // postScaleMatrix: Matrix to scale x, y to [0, 1] range\r\n  //   | g  0  0 |\r\n  //   | 0  h  0 |\r\n  //   | 0  0  1 |\r\n  const g = 1 / imageSize.width;\r\n  const h = 1 / imageSize.height;\r\n\r\n  // translateMatrix: Matrix to move the center to the subRect center.\r\n  //   | 1  0  e |\r\n  //   | 0  1  f |\r\n  //   | 0  0  1 |\r\n  const e = subRect.xCenter;\r\n  const f = subRect.yCenter;\r\n\r\n  // rotateMatrix: Matrix to do rotate the image around the subRect center.\r\n  //   | c -d  0 |\r\n  //   | d  c  0 |\r\n  //   | 0  0  1 |\r\n  const c = Math.cos(subRect.rotation);\r\n  const d = Math.sin(subRect.rotation);\r\n\r\n  // flipMatrix: Matrix for optional horizontal flip around the subRect center.\r\n  //   | fl 0  0 |\r\n  //   | 0  1  0 |\r\n  //   | 0  0  1 |\r\n  const flip = flipHorizontally ? -1 : 1;\r\n\r\n  // scaleMatrix: Matrix to scale x, y to subRect size.\r\n  //   | a  0  0 |\r\n  //   | 0  b  0 |\r\n  //   | 0  0  1 |\r\n  const a = subRect.width;\r\n  const b = subRect.height;\r\n\r\n  // initialTranslateMatrix: Matrix convert x, y to [-0.5, 0.5] range.\r\n  //   | 1  0 -0.5 |\r\n  //   | 0  1 -0.5 |\r\n  //   | 0  0  1   |\r\n\r\n  // M is a 3 by 3 matrix denoted by:\r\n  // | a0  a1  a2 |\r\n  // | b0  b1  b2 |\r\n  // | 0   0   1  |\r\n  // To use M with regular x, y coordinates, we need to normalize them first.\r\n  // Because x' = a0 * x + a1 * y + a2, y' = b0 * x + b1 * y + b2,\r\n  // we need to use factor (1/inputResolution.width) to normalize x for a0 and\r\n  // b0, similarly we need to use factor (1/inputResolution.height) to normalize\r\n  // y for a1 and b1.\r\n  // Also at the end, we need to de-normalize x' and y' to regular coordinates.\r\n  // So we need to use factor imageSize.width for a0, a1 and a2, similarly\r\n  // we need to use factor imageSize.height for b0, b1 and b2.\r\n  const a0 = (1 / inputResolution.width) * a * c * flip * g * imageSize.width;\r\n  const a1 = (1 / inputResolution.height) * -b * d * g * imageSize.width;\r\n  const a2 = (-0.5 * a * c * flip + 0.5 * b * d + e) * g * imageSize.width;\r\n  const b0 = (1 / inputResolution.width) * a * d * flip * h * imageSize.height;\r\n  const b1 = (1 / inputResolution.height) * b * c * h * imageSize.height;\r\n  const b2 = (-0.5 * b * c - 0.5 * a * d * flip + f) * h * imageSize.height;\r\n\r\n  return [a0, a1, a2, b0, b1, b2, 0, 0];\r\n}\r\n\r\nfunction validateSize(size: {width: number, height: number}, name: string) {\r\n  tf.util.assert(size.width !== 0, () => `${name} width cannot be 0.`);\r\n  tf.util.assert(size.height !== 0, () => `${name} height cannot be 0.`);\r\n}\r\n"]}},"error":null,"hash":"7d2a32a8b697b0016c38c2b3300da7b3","cacheData":{"env":{}}}